import dotenv from 'dotenv';
import { fileURLToPath } from 'url';
import path from 'path';
import express from 'express';
import bodyParser from 'body-parser';
import cors from 'cors';
import * as Minio from 'minio';
import { Job, JobScheduler, Queue, Worker } from 'bullmq';
import IORedis from 'ioredis';

// å¼•å…¥æ ¸å¿ƒå¥—ä»¶ (ESM)
import * as FRAGS from "@thatopen/fragments";
import * as WEBIFC from "web-ifc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// è®€å–ä¸Šä¸€å±¤çš„ .env
dotenv.config({ path: path.resolve(__dirname, '../.env') });

// === Redis é€£ç·šè¨­å®š ===
// é€™æ˜¯ BullMQ ç”¨ä¾†é€£ç·š Redis çš„è¨­å®š
const redisConnection = new IORedis({
    host: 'localhost',
    port: 6379,
    maxRetriesPerRequest: null, // BullMQ è¦æ±‚å¿…é ˆè¨­ç‚º null
})

// === 1. åˆå§‹åŒ– MinIO å®¢æˆ¶ç«¯ ===
const minioClient = new Minio.Client({
    endPoint: 'localhost',
    port: 9000,
    useSSL: false,
    accessKey: process.env.S3_ACCESS_KEY,
    secretKey: process.env.S3_SECRET_KEY
});

const IFC_BUCKET = process.env.S3_IFC_BUCKET;
const FRAG_BUCKET = process.env.S3_FRAGS_BUCKET;

// === 2. åˆå§‹åŒ– IfcImporter ===
const serializer = new FRAGS.IfcImporter();
serializer.wasm.path = "/"

// é€™å€‹ Queue ç”¨ä¾†è®“ Webhook æŠŠä»»å‹™ä¸Ÿé€²å»
const conversionQueue = new Queue('ifc-conversion-queue', { 
    connection: redisConnection 
});

const PORT = 3005;

async function executeConversionTask(job, fileKey, fileName) {
    console.log(`ğŸš€ [Job Start] é–‹å§‹è™•ç†: ${fileName} (Key: ${fileKey})`);
    
    
    // 1. ä¸‹è¼‰ IFC
    const stat = await minioClient.statObject(IFC_BUCKET, fileKey);
    const totalSize = stat.size;
    let downloadedSize = 0;

    console.log(`â¬‡ï¸ [MinIO] æ­£åœ¨ä¸‹è¼‰...`);
    const fileStream = await minioClient.getObject(IFC_BUCKET, fileKey);
    const chunks = [];
    for await (const chunk of fileStream) {
        chunks.push(chunk);
        downloadedSize += chunk.length;

        // ä¸‹è¼‰é€²åº¦ï¼š0% ~ 40%
        const percentage = Math.round((downloadedSize / totalSize) * 40);

        // ç°¡å–®ç¯€æµï¼šæ¯ 5% æ›´æ–°ä¸€æ¬¡
        if (percentage % 5 === 0){
            await job.updateProgress(percentage);
        }
    }

    const fileBuffer = Buffer.concat(chunks);
    console.log(`ğŸ“¦ [Worker] ä¸‹è¼‰å®Œæˆï¼Œå¤§å°: ${(fileBuffer.length / 1024 / 1024).toFixed(2)} MB`);

    // ==========================================
    // âš™ï¸ è½‰æ›éšæ®µ (ä½¿ç”¨ progressCallback)
    // ==========================================
    console.log(`âš™ï¸ [Convert] é–‹å§‹è½‰æª” (.frag)...`);
    // å®šç¾©ç¯€æµè®Šæ•¸ï¼Œé¿å… Redis è¢«callçˆ›
    let lastReportTime = 0;
    const start = performance.now();
    
    const modelData = await serializer.process({
        bytes: new Uint8Array(fileBuffer),
        progressCallback:(progress)=>{
            //progress 0-1
            const now = Date.now();
            // ç¯€æµï¼šæ¯ 1 ç§’æ‰å…è¨±æ›´æ–°ä¸€æ¬¡ Redis
            if((now - lastReportTime) > 1000){
                lastReportTime = now;

                // è½‰æ›éšæ®µé€²åº¦æ˜ å°„ï¼š40% ~ 90%
                // å…¬å¼ï¼š 40 + (progress * 0.5)
                const totalProgress = Math.round(40 + (progress * 50));

                job.updateProgress(totalProgress).catch(e => console.error(e));
            }
            console.log(`æ­£åœ¨é€²è¡Œ${job.id}è½‰æª”,ç¸½é€²åº¦ç‚º${progress}`);
        }
    });
    const duration = (performance.now() - start) / 1000;
    console.log(`âœ… [Convert] è½‰æª”æˆåŠŸï¼è€—æ™‚: ${duration.toFixed(2)}s`);
    // ==========================================
    // â¬†ï¸ ä¸Šå‚³éšæ®µ
    // ==========================================
    // æ‰‹å‹•æ›´æ–°åˆ° 90% (è½‰æª”å®Œæˆ)
    await job.updateProgress(90);
    const fragKey = fileKey + '.frag'; 
    const fragBuffer = Buffer.from(modelData);

    const bucketExists = await minioClient.bucketExists(FRAG_BUCKET);
    if (!bucketExists) {
        await minioClient.makeBucket(FRAG_BUCKET);
    }

    console.log(`â¬†ï¸ [MinIO] ä¸Šå‚³ .frag æª”æ¡ˆ: ${fragKey}`);
    await minioClient.putObject(FRAG_BUCKET, fragKey, fragBuffer);
    // å®Œæˆï¼æ›´æ–°åˆ° 100%
    await job.updateProgress(100);

    console.log(`ğŸ‰ [Job Done] ä»»å‹™å®Œæˆï¼`);
    return { fileKey, fileName, fragKey }; // å›å‚³çµæœçµ¦ Worker äº‹ä»¶
}

// é€™æ˜¯çœŸæ­£æœƒåœ¨èƒŒæ™¯ã€Œä¸€å€‹æ¥ä¸€å€‹ã€åŸ·è¡Œä»»å‹™çš„å·¥äºº
// æœƒå»æª¢æŸ¥redisé‚„æœ‰æ²’æœ‰å·¥ä½œ
const worker = new Worker('ifc-conversion-queue', async (job) => {
    // job.data åŒ…å«æˆ‘å€‘åœ¨ Webhook è£¡ä¸Ÿé€²å»çš„ { fileKey, fileName }
    const { fileKey, fileName } = job.data;
    
    // åŸ·è¡Œè½‰æª”
    return await executeConversionTask(job, fileKey, fileName);

}, {
    connection: redisConnection,
    concurrency: 1 // ğŸ”¥ é—œéµï¼åŒæ™‚åªèƒ½æœ‰ 1 å€‹ä»»å‹™åœ¨è·‘ (é¿å… OOM)
});

// ç›£è½ Worker äº‹ä»¶ (é€šçŸ¥ Tus Server)

// æˆåŠŸæ™‚é€šçŸ¥
worker.on('completed', async (job, result) => {
    const { fileKey, fileName } = job.data;
    console.log(`ğŸ“ [Worker] Job ${job.id} å®Œæˆï¼Œé€šçŸ¥ Server...`);

    try {
        await fetch('http://localhost:3003/notify/done', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                fileKey: fileKey,
                fileName: fileName,
                status: 'success'
            })
        });
    } catch (e) {
        console.error("âŒ ç„¡æ³•é€šçŸ¥ Server (Success):", e.message);
    }
});
// å¤±æ•—æ™‚é€šçŸ¥
worker.on('failed', async (job, err) => {
    const { fileKey, fileName } = job.data;
    console.error(`âŒ [Worker] Job ${job.id} å¤±æ•—: ${err.message}`);

    try {
        await fetch('http://localhost:3003/notify/done', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                fileKey: fileKey,
                fileName: fileName,
                status: 'error',
                message: err.message
            })
        });
    } catch (e) {
        console.error("âŒ ç„¡æ³•é€šçŸ¥ Server (Error):", e.message);
    }
});

// === è¨­å®š Web Server(Webhook å…¥å£) ===
const app = express();
app.use(cors());
app.use(bodyParser.json());

app.post('/webhook/convert', async(req, res) => {
    const { fileKey, fileName } = req.body;
    
    if (!fileKey || !fileName) {
        return res.status(400).send({ error: 'Missing fileKey or fileName' });
    }

    // æŠŠä»»å‹™åŠ å…¥ä½‡åˆ—ï¼Œç„¶å¾Œé¦¬ä¸Šå›æ‡‰
    try {
        await conversionQueue.add('convert-job', { 
            fileKey, 
            fileName 
        },{
            jobId: fileKey, //å¼·åˆ¶æŠŠ Job ID è¨­å®šæˆè·Ÿ fileKey ä¸€æ¨£ï¼
            // è¨­å®šè‡ªå‹•æ¸…ç† (é‡è¦!!!!!!)
            removeOnComplete: {
                age: 3600, // ä¿ç•™ 1 å°æ™‚å…§çš„ç´€éŒ„ (ç§’)
                count: 100 // æˆ–è€…æœ€å¤šä¿ç•™æœ€æ–°çš„ 100 ç­†
            },
            removeOnFail: {
                age: 24 * 3600, // å¤±æ•—çš„ä¿ç•™ 24 å°æ™‚è®“æˆ‘å€‘æŸ¥ä¿®
                count: 50
            }
        });

        console.log(`ğŸ“¨ [Webhook] å·²å°‡ ${fileName} åŠ å…¥ä½‡åˆ—ç­‰å¾…è™•ç†`);
        
        // é€™è£¡å›æ‡‰ 200ï¼Œå‘Šè¨´ Tus Server "æˆ‘æ”¶åˆ°äº†ï¼Œæ­£åœ¨æ’éšŠä¸­"
        // å‰ç«¯æœƒé¡¯ç¤º "Converting..." (å› ç‚º Tus Server å°šæœªå»£æ’­ success)
        res.status(200).send({ status: 'Queued', message: 'Job added to queue' });

    } catch (err) {
        console.error("âŒ ç„¡æ³•åŠ å…¥ä½‡åˆ—:", err);
        res.status(500).send({ error: 'Queue Error' });
    }
});

app.listen(PORT, () => {
    console.log(`--------------------------------------------------`);
    console.log(`ğŸ‘· IfcImporter Worker (ESM) Listening on port ${PORT}`);
    console.log(`ğŸ‘· IfcImporter Work List on port ${redisConnection.options.port}`);
    console.log(`ğŸ‚ BullMQ Worker Started with Concurrency: 1`);
    console.log(`--------------------------------------------------`);
});